# 问题及回答

### 1）你使用了FLume+Spark-Streaming+Redis这一套实时流数据采集和处理架构，为什么没有在里面加入Kafka这个常用的数据传输队列呢？

- Flume的channel本身具有消息队列的功能
- 这套架构调试了很久才调试通，害怕新加入一个组件导致崩溃（框架的版本问题）

首先，我们最开始做的这个架构就是 Flume+Spark-Streaming 这个架构，因为 Flume 本身是有传输队列这个功能的，因为Flume+SparkStreaming这个架构的成功实现，以及Spark-Streaming程序成功跑起来，花了很长的时间（最开始用Python来编写streaming程序，后面实在不行，使用Scala编写Streaming程序），在中间在加上一个Kafka的话，两边的配置以及Streaming的程序要改动，不知道还能否配置成功。



channel：

为了更快的交付，选择了memory channel，高可靠性的话，选择file channel



### 2）Flume与Spark-Streaming对接使用了什么方式？为什么选择这种方式？

- **Flume-Push 方式**
- Flume-Push 和 Flume-Pull 的**区别**，Flume-Push 的有点

在本系统中使用的是 FLume-Push 的方式，还有另一种方式是 Flume-Pull，Flume-Pull方式是Spark-Streaming主动获取数据，FLume-Push是Spark-Streaming被动获取数据， push模式的目标是尽可能以最快速度传递消息 



### 3）HDFS里面的数据是怎么存的？

- 目录结构
- 文件命名方式
- Flume 对接 HDFS 的方法

我们在HDFS里面建立了一个分区（文件夹，叫user_behavior），在这个分区里面，以events-.存储时的时间戳为文件名，在Flume设置的存储到HDFS的存储机制是，每传输过来5条用户行为数据，就保存到一个文件中，里面存储的内容是传输的 Json 数据里面 body字段对应的值



### 4）为什么要是使用 Flume 来收集日志

- **Flume 的优点**

**优点**

>  Flume是一个分布式的、高可靠性、高可用的日志收集框架，它可以自由地定制数据的发送方，数据的发送方可以是来自Http、Tcp的数据包，可以是Kafka、Log4J等框架，数据的接收方可以是 HDFS、HBase、MySQL等框架和数据库





你这个架构是在单机上以 standalone 的方式运行的，并没有什么意义啊？

- 成本问题
- 确实准备不够充分
- 我们是构思过集群版的设计的



### 如果让你进行集群的设计，你会如何设计？

- **Flume 集群设计**
- **Hadoop** **集群设计**
- **Spark 集群设计**



**Flume 集群设计（围绕Flume高可用的特性）**

假设我们有三台机器，node1、node2、node3，让 node1 同时作为 agent 和 collector，node2 作为 collector，node3 作为 agent，并设置两个 collector 的优先级，node2 的优先级更高，node1 的优先级更低



**Hadoop 集群设计**

一台作为 NameNode，另外两台作为 DataNode

NameNode 是用来存储元数据的，就是整个文件系统的目录信息，文件信息，分块信息

DataNode 是用来存储 Block 块的

> 大文件的存储？
> 大文件被分成默认64M一块的数据块（称之为Block），以冗余镜像的方式存储在不同机器中



**Spark 集群设计**

一个Master、两个Worker

 

#### 你的文档里面提到了合并 User 信息，但是你现在的小程序里面，用户注册的时候并不需要填写 User 的信息啊？



#### 能收集到一千多条的信息吗？

是可以的，我们大概找了10来个人，让他们长期使用一段时间。



### 5）要传输的 Json 的格式的怎么样的？

Flume里面规定了，接收的 Json 必须要是只能有两个字段 headers 和 body，我们这里的话，是将要实时传输的内容到 headers 里面，要存入 HDFS 的内容放到 body 里面

![1593166343137](C:\Users\Liang\AppData\Roaming\Typora\typora-user-images\1593166343137.png)



### 6）为什么要使用Redis？Redis里面的数据是如何存储的？

因为要实时地存储和提取古诗的标签，Redis 是比较常用的缓存数据库，它的搜索速度是相对比较快的，适合我们这里的使用场景，而且 Redis 的生态非常好，常用的编程语言都可以轻松地找到操作 Redis 的库

Redis数据的存储，是以用户的 id 为键，值是使用 list 的数据结构，含有诗歌标签的字符串为元素值进行存储的



### 7）Spark-Streaming在这里做了什么事情？

将 FLume 传过来的 Json 数据，Spark-Streaming将通过将Flume-event事件转换为Dstream，将Dstream以RDD的方式进行处理，具体的话，就是提取出这个dstream里面的headers部分，然后通过内置的 Json 库，将其转换为内置的对象，在进行各种字符串的处理，最后提取出里面的内容存入Redis



### 7.5）关于Spark-Streaming原理的问题。。

Spark Streaming最主要的抽象是DStream(Discretized Stream,离散化数据流)，表示连续不断的数据流。在内部实现上，Spark Streaming的输入数据按照时间片（例如1秒）分成一段段的DStream，每一段数据转换为Spark的RDD,并且对DStream的操作都最终转换为相应的RDD操作。



### 8）为什么会使用Mongodb？

- Mongodb 的特点
- 个人偏好：使用方便，速度也快

 因为Mongodb是以键值对的形式进行存储的，Mongodb非常适合实时的插入，更新与查询，非常适合我们的实时负样本采集，根据标签查询的使用场景



### 9）讲一下 Word2Vec 的原理？

**概念**：因为NLP里面最细粒度的东西就是词语，我们需要将文本类型的词语用数学的形式表示出来，就要用词向量表示，得到词向量的一种方法就是**词嵌入**，Word2Vec是一种词嵌入的方法，Word2Vec有两种模型分别是Skip-gram和CBOW模型

我们这里使用的是CBOW模型，他是由一个输入层，一个隐藏层，一个输出层组成的，它们都是全连接的，隐藏层的维数是认为设定的，表示每个词对应的词向量的维数，隐藏层使用的激活函数是线性的，没有使用ReLu等非线性的激活函数，输入层输入的是每一个词的独热向量，输出层输出的是这个词出现的上下文的各个词的独热向量（只不过里面不是1，而是用概率表示），使用反向传播算法进行模型的训练，最后要得到的是输入层和隐藏层之间的权重矩阵。



 <img src="https://pic3.zhimg.com/80/v2-d1ca2547dfb91bf6a26c60782a26aa02_720w.jpg" alt="img" style="zoom: 67%;" /> 



### 10）讲一下 Logistics Regression 的原理

就是给每一个特征一个参数，对每个特征的值进行线性加权得到一个连续值，对这个连续值进行 Sigmoid 变换，得到一个二分类的离散值，使用梯度下降法进行模型的训练（模型训练=参数迭代更新）

其主要参数有正则项系数C，和最大迭代次数max_iter，正则项系数C越小，对损失函数惩戒约严重，即交叉熵损失函数的影响越小

L2正则项：
$$
\min_{w, c} \frac{1}{2}w^T w + C \sum_{i=1}^n \log(\exp(- y_i (X_i^T w + c)) + 1) .
$$
L1正则项：
$$
\min_{w, c} \|w\|_1 + C \sum_{i=1}^n \log(\exp(- y_i (X_i^T w + c)) + 1).
$$
L1 正则项会过滤掉很多特征，更使用与特征筛选，一般情况下，还是 L2 正则项用得比较多



### 11）讲一下 SVD 的原理

SVD算法是基于矩阵分解算法进行改进的，假设当前有 M 个用户，N 首古诗，那么要预测的用户-诗词矩阵是一个M*N 的矩阵，对于这个 M\*N 的矩阵，我们是只知道里面的一部分的（根据用户行为数据计算出一部分），我们要计算的是剩下的空缺的用户-诗词的评分，于是我们可以将M\*N的矩阵分解为 M\*k 的用户向量乘以 k\*N 的诗词向量，其中 k 是隐因子的数量，用这两个矩阵相乘来填满整个用户-诗词矩阵，SVD是在这个的基础上加上了用户偏置分，物品偏置分，和全局平均分这几个需要训练的参数，训练出来的模型更准确，使用梯度下降法进行模型的训练，参数的更新。



### 12）讲一下 Xgboost 的原理

Xgboost是一个集成模型，使用梯度提升的方式继续模型的训练，并且他是一个加法模型，输出的结果是每一个基模型的输出的加和，原理太多了，这里就不细讲了



### 13）讲一下 Xgboost + LR 融合模型的实现

使用Xgboost模型的apply方法，得到每个样本落在的每个基模型的叶子节点的位置（以编号表示），对这个数据使用独热编码，将样本落在的叶子节点的编号标为1，其他标为0，使用Xgboost的这种方式，对特征进行编码，在将编码后的特征用作LR模型的输入。



### 14）讲一下SVD模型的调优？

使用网格搜索，要调优的参数有隐因子数量，梯度下降的最大迭代次数，偏置项的正则项系数，偏置项的学习率，最终得到的RMSE是2.49



### 15）为什么会选择Xgboost+LR模型，它的优势在哪里？

因为LR模型是线性模型，学习能力有限，使用Xgboost算法**可以发掘有效的的特征和特征组合**，减少特征工程的人力成本，而且是当前使用比较广泛的一种融合模型，因为一个样本点更具它的特征从树的根部到叶子节点的过程所经过的节点可以看作是某种特征组合。



为什么Xgboost可以发掘有效的特征和特征组合？

这个问题可以转化为，样本进入决策树，是如何从根节点落入叶子节点的



### 16）讲一下 Xgboost+LR 模型的调优？

调优参数的主要做法：先对Xgboost进行调参，在对使用了Xgboost做特征编码的LR调参

Xgboost调参：以AUC为指标讲Xgboost跳到最优，使用初始化参数得到的Xgboost模型的AUC为0.69，参数调到最优的Xgboost模型的AUC为0.72

参数调优的顺序：

首先初始化必要的参数值（比如树的最大深度，基模型的数量等），**以较高学习率**，进行调参

各个参数的意义：

max_depth：树的深度

min_weight：最小样本权重和， 当它的值较大时，可以避免模型学习到局部的特殊样本 

gamma： 在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值 

subsample： 这个参数控制对于每棵树，随机采样的比例 

colsample_bytree： 用来控制每棵随机采样的列数的占比(每一列是一个特征) 

reg_alpha：正则项系数



### 17）讲一下AUC吧

AUC 是 ROC 曲线下的面积，ROC曲线是以FP Rate 为横轴，TP Rate 为纵轴绘制的曲线，对于样本，类别为1称为Positive，类别为0称为Negative，模型预测正确的样本为True，预测错误的样本为False，对这些概念进行组合，便可以得到混淆矩阵。根据混淆矩阵便可以得到 FP rate 和 TP rate



### 18) TFIDF是啥？

TFIDF = TF值*IDF值，TF 是词频，IDF 值表示反文档频率，可以表示这个词对于不同诗词类别的区分度

反文档频率：
$$
IDF = log(\frac{语料库的文档总数}{包含词条w的文档数+1})
$$
，对于每首诗词中重要性较高的词，其对应计算得到的 TFIDF 值是越大的



### 19）看Spark Word2Vec那块的源码

==那个Jupyter再看几遍==



### 20）如何检验你们这个推荐系统的推荐效果？

<font color="red">此时直接打开文档对应的位置，展示模型指标的对比。。</font>

由于现实环境中使用的用户数量还是比较少，仅局限于部分的老师和同学，所以并不能具体的测出推荐的效果如何，但是根据我们组内成员这两三个月的使用，我们对其推荐结果还是比较满意的，我们虽然无法测试出其推荐的效果，==但是我们在技术层面是尽量做到最优的==，比如在召回模型这块我们对比了传统的MF算法和SVD算法，发现SVD算法的RMSE指标较优，于是对SVD模型使用网格搜索将参数调到最优的，在排序模型这块我们是对比了4个常用的模型的效果，选出最优的模型，并把这个模型的参数调到最优的，我们跳到最优的Xgboot+LR模型比使用初始化参数的Xgboot+LR模型的AUC整整高6个百分点，最优的 AUC 是0.869